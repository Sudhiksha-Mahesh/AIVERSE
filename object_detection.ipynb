{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKvdLLLQ7h_a",
        "outputId": "b348a4e8-69df-4071-d037-dcc40ed3c100",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 960ms\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit ultralytics supervision opencv-python-headless pillow python-magic numpy pandas\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iDfEp1jy70qi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p src/utils\n",
        "!mkdir -p model\n",
        "!mkdir -p output\n",
        "!mkdir -p sample_images\n",
        "!mkdir -p sample_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgJvTlhd72UX",
        "outputId": "931218f4-5e7b-4951-b34c-2b341826bf17",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-13 15:57:05--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250413%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250413T155705Z&X-Amz-Expires=300&X-Amz-Signature=3371f64ab7b1e58cade034f9f34d87aaeb50d719fdaf36e0969532d585b282fe&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-13 15:57:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250413%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250413T155705Z&X-Amz-Expires=300&X-Amz-Signature=3371f64ab7b1e58cade034f9f34d87aaeb50d719fdaf36e0969532d585b282fe&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6534387 (6.2M) [application/octet-stream]\n",
            "Saving to: ‚Äòmodel/yolov8n.pt‚Äô\n",
            "\n",
            "\rmodel/yolov8n.pt      0%[                    ]       0  --.-KB/s               \rmodel/yolov8n.pt    100%[===================>]   6.23M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-13 15:57:05 (266 MB/s) - ‚Äòmodel/yolov8n.pt‚Äô saved [6534387/6534387]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt -O model/yolov8n.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbVnJTl73tk",
        "outputId": "e32c476a-672a-4f32-bcc3-965186fbda9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/__init__.py\n",
        "# Makes src a Python package\n",
        "from .detect import ObjectDetector\n",
        "from .image_test import process_image, process_directory\n",
        "from .video_test import process_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdTSj17Q756k",
        "outputId": "ef132b57-afaa-49a6-eed7-3dd88be1f78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/utils/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/utils/__init__.py\n",
        "# Makes utils a Python package\n",
        "from .security import validate_file_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y0RQbWhQYC1",
        "outputId": "0f7feb15-9869-4ab7-edbf-085b3df344ad",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/detect.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/detect.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class ObjectDetector:\n",
        "    def __init__(self, model_path='model/yolov8n.pt'):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.class_names = self.model.names\n",
        "\n",
        "    def detect(self, image):\n",
        "        results = self.model(image)[0]\n",
        "        boxes = results.boxes.xyxy.cpu().numpy()\n",
        "        classes = results.boxes.cls.cpu().numpy()\n",
        "        confidences = results.boxes.conf.cpu().numpy()\n",
        "        return boxes, classes, confidences\n",
        "\n",
        "    def annotate_image(self, image, boxes, classes, confidences, confidence_threshold=0.5):\n",
        "        annotated_image = image.copy()\n",
        "        for box, cls, conf in zip(boxes, classes, confidences):\n",
        "            if conf < confidence_threshold:\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            label = f\"{self.class_names[int(cls)]} {conf:.2f}\"\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Draw label background\n",
        "            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "            cv2.rectangle(annotated_image, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "            # Draw text\n",
        "            cv2.putText(annotated_image, label, (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "        return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhLjIoTaQcFc",
        "outputId": "6f3996f0-bb55-461d-f34c-c6477047de80",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/image_test.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/image_test.py\n",
        "from src.detect import ObjectDetector\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def process_image(image_path, output_dir='output', confidence_threshold=0.5):\n",
        "    detector = ObjectDetector()\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(\"Could not read image\")\n",
        "\n",
        "    boxes, classes, confidences = detector.detect(image)\n",
        "    annotated_image = detector.annotate_image(image, boxes, classes, confidences, confidence_threshold)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
        "    cv2.imwrite(output_path, annotated_image)\n",
        "    return output_path, (boxes, classes, confidences)\n",
        "\n",
        "def process_directory(directory_path, output_dir='output', confidence_threshold=0.5):\n",
        "    image_paths = [os.path.join(directory_path, f) for f in os.listdir(directory_path)\n",
        "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    results = []\n",
        "    for img_path in image_paths:\n",
        "        output_path, _ = process_image(img_path, output_dir, confidence_threshold)\n",
        "        results.append(output_path)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import streamlit as st\n",
        "from src.detect import ObjectDetector\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_video(\n",
        "    video_path,\n",
        "    output_path='output/output_video.mp4',\n",
        "    confidence_threshold=0.5,\n",
        "    frame_skip=1,\n",
        "    show_progress=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Process video with YOLO object detection\n",
        "\n",
        "    Args:\n",
        "        video_path: Input video path\n",
        "        output_path: Output video path\n",
        "        confidence_threshold: Detection confidence (0-1)\n",
        "        frame_skip: Process every nth frame (for faster processing)\n",
        "        show_progress: Show progress bar in Streamlit\n",
        "\n",
        "    Returns:\n",
        "        output_path: Path to processed video\n",
        "    \"\"\"\n",
        "    detector = ObjectDetector()\n",
        "    start_time = time.time()\n",
        "    temp_files = []\n",
        "    cap = None\n",
        "    out = None\n",
        "\n",
        "    try:\n",
        "        # Open video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video: {video_path}\")\n",
        "\n",
        "        # Get video properties\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Validate video\n",
        "        if fps <= 0 or total_frames <= 0:\n",
        "            raise ValueError(\"Invalid video properties (FPS or frame count)\")\n",
        "\n",
        "        # Prepare output\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "        # Try multiple codecs in order of preference\n",
        "        codecs = ['avc1', 'X264', 'mp4v']\n",
        "        for codec in codecs:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*codec)\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "            if out.isOpened():\n",
        "                break\n",
        "\n",
        "        if not out or not out.isOpened():\n",
        "            raise ValueError(\"Failed to create output video with any codec\")\n",
        "\n",
        "        # Progress tracking\n",
        "        progress_bar = st.progress(0) if show_progress else None\n",
        "        status_text = st.empty() if show_progress else None\n",
        "\n",
        "        # Process frames\n",
        "        frame_count = 0\n",
        "        processed_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Skip frames if requested\n",
        "            if frame_count % frame_skip != 0:\n",
        "                frame_count += 1\n",
        "                continue\n",
        "\n",
        "            # Detect objects\n",
        "            boxes, classes, confidences = detector.detect(frame)\n",
        "            annotated_frame = detector.annotate_image(\n",
        "                frame, boxes, classes, confidences, confidence_threshold\n",
        "            )\n",
        "            out.write(annotated_frame)\n",
        "            processed_count += 1\n",
        "\n",
        "            # Update progress\n",
        "            if show_progress:\n",
        "                progress = min(1.0, frame_count / total_frames)\n",
        "                progress_bar.progress(progress)\n",
        "                status_text.text(\n",
        "                    f\"Processed {processed_count}/{total_frames} frames \"\n",
        "                    f\"({frame_skip}x skip) | \"\n",
        "                    f\"Elapsed: {time.time()-start_time:.1f}s\"\n",
        "                )\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        # Explicitly release the video writer\n",
        "        out.release()\n",
        "\n",
        "        # Verify the output file was created\n",
        "        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "            raise RuntimeError(\"Output video file was not created properly\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Cleanup on error\n",
        "        if os.path.exists(output_path):\n",
        "            os.remove(output_path)\n",
        "        raise RuntimeError(f\"Video processing failed: {str(e)}\")\n",
        "\n",
        "    finally:\n",
        "        # Release resources\n",
        "        if cap is not None and cap.isOpened():\n",
        "            cap.release()\n",
        "        if out is not None and out.isOpened():\n",
        "            out.release()\n",
        "\n",
        "        # Clean temp files\n",
        "        for f in temp_files:\n",
        "            if os.path.exists(f):\n",
        "                os.remove(f)"
      ],
      "metadata": {
        "id": "-Mz3EBYGby9c"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHPeIwbeZ9ti",
        "outputId": "cb626b60-7219-4348-de40-baa3dcbb7226",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/utils/security.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/utils/security.py\n",
        "import magic\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os  # <-- THIS WAS MISSING\n",
        "\n",
        "def validate_file_upload(file):\n",
        "    # Allowed video MIME types\n",
        "    VIDEO_TYPES = [\n",
        "        'video/mp4',\n",
        "        'video/x-msvideo',  # AVI\n",
        "        'video/quicktime',  # MOV\n",
        "        'video/x-matroska' # MKV\n",
        "    ]\n",
        "\n",
        "    # Validate image files\n",
        "    if file.type.startswith('image/'):\n",
        "        try:\n",
        "            img = Image.open(BytesIO(file.getvalue()))\n",
        "            img.verify()\n",
        "            return True\n",
        "        except Exception:\n",
        "            raise ValueError(\"Invalid image file - corrupted or unsupported format\")\n",
        "\n",
        "    # Validate video files\n",
        "    elif file.type in VIDEO_TYPES:\n",
        "        try:\n",
        "            # Save temporary file\n",
        "            temp_path = f\"temp_{file.name}\"\n",
        "            with open(temp_path, \"wb\") as f:\n",
        "                f.write(file.getbuffer())\n",
        "\n",
        "            # Check if OpenCV can read it\n",
        "            cap = cv2.VideoCapture(temp_path)\n",
        "            if not cap.isOpened():\n",
        "                raise ValueError(\"Unsupported video codec\")\n",
        "            if cap.get(cv2.CAP_PROP_FRAME_COUNT) < 1:\n",
        "                raise ValueError(\"Corrupted video (no frames detected)\")\n",
        "            cap.release()\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Video error: {str(e)}\")\n",
        "        finally:\n",
        "            # Clean up temp file\n",
        "            if os.path.exists(temp_path):\n",
        "                os.remove(temp_path)\n",
        "\n",
        "    raise ValueError(f\"Unsupported file type: {file.type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iADDhshE8Fjz",
        "outputId": "df0342b9-2ff1-4e51-ec1e-fa9a7dd621cf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import warnings  # <-- For handling JS warnings\n",
        "\n",
        "# ===== 1. FIRST configure page settings =====\n",
        "st.set_page_config(\n",
        "    page_title=\"Object Detection (Colab)\",\n",
        "    page_icon=\"üîç\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ===== 2. THEN add warning filters =====\n",
        "warnings.filterwarnings(\"ignore\", message=\".*Failed to fetch dynamically imported module.*\")\n",
        "\n",
        "# ===== 3. THEN import your custom modules =====\n",
        "from src.image_test import process_image, process_directory\n",
        "from src.video_test import process_video\n",
        "from src.utils.security import validate_file_upload\n",
        "from src.detect import ObjectDetector\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .stButton>button { background-color: #4CAF50; color: white; }\n",
        "    .stFileUploader>div>div>button { background-color: #4CAF50; color: white; }\n",
        "    .css-1aumxhk { background-color: #f0f2f6; border-radius: 10px; padding: 20px; }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"Object Detection in Colab\")\n",
        "st.write(\"Upload files or use sample data\")\n",
        "\n",
        "# Create sample data directory\n",
        "os.makedirs(\"sample_images\", exist_ok=True)\n",
        "os.makedirs(\"sample_videos\", exist_ok=True)\n",
        "\n",
        "# Mode selection\n",
        "mode = st.sidebar.radio(\n",
        "    \"Select Mode\",\n",
        "    [\"Single Image\", \"Image Directory\", \"Video File\"],\n",
        "    index=0\n",
        ")\n",
        "\n",
        "confidence_threshold = st.sidebar.slider(\n",
        "    \"Confidence Threshold\",\n",
        "    0.0, 1.0, 0.5, 0.05\n",
        ")\n",
        "\n",
        "def download_sample_file(url, save_path):\n",
        "    \"\"\"Download sample files using Python instead of !wget\"\"\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, save_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to download sample file: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "if mode == \"Single Image\":\n",
        "    st.header(\"Image Detection\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        uploaded_file = st.file_uploader(\"Upload image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "        use_sample = st.checkbox(\"Use sample image\")\n",
        "\n",
        "    if use_sample or uploaded_file:\n",
        "        try:\n",
        "            if use_sample:\n",
        "                sample_url = \"https://ultralytics.com/images/zidane.jpg\"\n",
        "                sample_path = \"sample_images/zidane.jpg\"\n",
        "                if download_sample_file(sample_url, sample_path):\n",
        "                    image_path = sample_path\n",
        "                    image = Image.open(image_path)\n",
        "            else:\n",
        "                validate_file_upload(uploaded_file)\n",
        "                image = Image.open(uploaded_file)\n",
        "                image_path = f\"temp_{uploaded_file.name}\"\n",
        "                image.save(image_path)\n",
        "\n",
        "            col2.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "\n",
        "            if st.button(\"Detect Objects\"):\n",
        "                with st.spinner(\"Processing...\"):\n",
        "                    output_path, detections = process_image(\n",
        "                        image_path,\n",
        "                        confidence_threshold=confidence_threshold\n",
        "                    )\n",
        "                    result_image = Image.open(output_path)\n",
        "                    st.image(result_image, caption=\"Detected Objects\")\n",
        "\n",
        "                    with st.expander(\"Detection Metrics\"):\n",
        "                        st.json({\n",
        "                            \"Total Detections\": len(detections),\n",
        "                            \"Classes\": list(set(detections.class_id)),\n",
        "                            \"Avg Confidence\": float(np.mean(detections.confidence))\n",
        "                        })\n",
        "\n",
        "                        df = pd.DataFrame({\n",
        "                            \"Class\": [detector.class_names[cls] for cls in detections.class_id],\n",
        "                            \"Confidence\": detections.confidence,\n",
        "                            \"Area\": detections.area\n",
        "                        })\n",
        "                        st.dataframe(df)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")\n",
        "\n",
        "elif mode == \"Image Directory\":\n",
        "    st.header(\"Batch Image Processing\")\n",
        "    uploaded_files = st.file_uploader(\n",
        "        \"Upload images\",\n",
        "        type=[\"jpg\", \"jpeg\", \"png\"],\n",
        "        accept_multiple_files=True\n",
        "    )\n",
        "    use_sample = st.checkbox(\"Use sample images\")\n",
        "\n",
        "    if use_sample or uploaded_files:\n",
        "        try:\n",
        "            if use_sample:\n",
        "                sample_urls = [\n",
        "                    \"https://ultralytics.com/images/bus.jpg\",\n",
        "                    \"https://ultralytics.com/images/zidane.jpg\"\n",
        "                ]\n",
        "                sample_paths = [\n",
        "                    \"sample_images/bus.jpg\",\n",
        "                    \"sample_images/zidane.jpg\"\n",
        "                ]\n",
        "                for url, path in zip(sample_urls, sample_paths):\n",
        "                    if not download_sample_file(url, path):\n",
        "                        raise Exception(\"Failed to download sample images\")\n",
        "                image_paths = sample_paths\n",
        "            else:\n",
        "                for file in uploaded_files:\n",
        "                    validate_file_upload(file)\n",
        "                image_paths = [f\"temp_{file.name}\" for file in uploaded_files]\n",
        "                for file, path in zip(uploaded_files, image_paths):\n",
        "                    with open(path, \"wb\") as f:\n",
        "                        f.write(file.getbuffer())\n",
        "\n",
        "            if st.button(\"Process Images\"):\n",
        "                with st.spinner(\"Processing...\"):\n",
        "                    results = []\n",
        "                    for path in image_paths:\n",
        "                        output_path, _ = process_image(\n",
        "                            path,\n",
        "                            confidence_threshold=confidence_threshold\n",
        "                        )\n",
        "                        results.append(output_path)\n",
        "\n",
        "                    st.success(f\"Processed {len(results)} images\")\n",
        "                    cols = st.columns(2)\n",
        "                    for i, path in enumerate(results):\n",
        "                        img = Image.open(path)\n",
        "                        cols[i%2].image(img, use_column_width=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")\n",
        "\n",
        "elif mode == \"Video File\":\n",
        "    st.header(\"Video Processing\")\n",
        "    uploaded_file = st.file_uploader(\"Upload video\", type=[\"mp4\", \"avi\", \"mov\"])\n",
        "    use_sample = st.checkbox(\"Use sample video\")\n",
        "\n",
        "    if use_sample or uploaded_file:\n",
        "        try:\n",
        "            if use_sample:\n",
        "                sample_url = \"https://ultralytics.com/videos/people.mp4\"\n",
        "                sample_path = \"sample_videos/people.mp4\"\n",
        "                if download_sample_file(sample_url, sample_path):\n",
        "                    video_path = sample_path\n",
        "            else:\n",
        "                validate_file_upload(uploaded_file)\n",
        "                video_path = f\"temp_{uploaded_file.name}\"\n",
        "                with open(video_path, \"wb\") as f:\n",
        "                    f.write(uploaded_file.getbuffer())\n",
        "\n",
        "            # ===== Display Original Video (Reliable Method) =====\n",
        "            with open(video_path, 'rb') as original_video:\n",
        "                original_bytes = original_video.read()\n",
        "            st.video(original_bytes)\n",
        "\n",
        "            if st.button(\"Process Video\"):\n",
        "                with st.spinner(\"Processing...\"):\n",
        "                    output_path = process_video(\n",
        "                        video_path,\n",
        "                        confidence_threshold=confidence_threshold\n",
        "                    )\n",
        "                    st.success(\"Processing complete!\")\n",
        "\n",
        "                    # ===== Display Processed Video (Reliable Method) =====\n",
        "                    try:\n",
        "                        with open(output_path, 'rb') as result_video:\n",
        "                            result_bytes = result_video.read()\n",
        "                        st.video(result_bytes)\n",
        "\n",
        "                        # Optional: Add a download button\n",
        "                        st.download_button(\n",
        "                            label=\"Download Processed Video\",\n",
        "                            data=result_bytes,\n",
        "                            file_name=\"processed_video.mp4\",\n",
        "                            mime=\"video/mp4\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Failed to display video: {str(e)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vd7AYdR85Il",
        "outputId": "60333e3d-769a-442e-8a6d-495d674b0f00",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.86.123.220"
          ]
        }
      ],
      "source": [
        "!curl ifconfig.me"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjtF7ELiPEs6",
        "outputId": "a57d5f94-0b5d-4e87-c935-873bbcbf96c8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/tmp/colab_runtime.sock': Device or resource busy\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /tmp/*  # Clear temp files\n",
        "import importlib\n",
        "importlib.invalidate_caches()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSQ05bCiSaWQ",
        "outputId": "9391fa50-2e68-44e8-b487-9ada91d02bd9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.123.220:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kyour url is: https://slimy-taxis-remain.loca.lt\n",
            "\u001b[31m‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m640\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mapp.py\u001b[0m:\u001b[94m21\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 18 \u001b[0mwarnings.filterwarnings(\u001b[33m\"\u001b[0m\u001b[33mignore\u001b[0m\u001b[33m\"\u001b[0m, message=\u001b[33m\"\u001b[0m\u001b[33m.*Failed to fetch dynamically impor\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 19 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 20 \u001b[0m\u001b[2m# ===== 3. THEN import your custom modules =====\u001b[0m                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m 21 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96msrc\u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mimage_test\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m process_image, process_directory\u001b[0m                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 22 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msrc\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mvideo_test\u001b[0m \u001b[94mimport\u001b[0m process_video                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 23 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msrc\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mutils\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96msecurity\u001b[0m \u001b[94mimport\u001b[0m validate_file_upload                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 24 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msrc\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mdetect\u001b[0m \u001b[94mimport\u001b[0m ObjectDetector                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/src/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# Makes src a Python package\u001b[0m                                                     \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m2 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96m.\u001b[0m\u001b[4;96mdetect\u001b[0m \u001b[94mimport\u001b[0m ObjectDetector                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m3 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96m.\u001b[0m\u001b[4;96mimage_test\u001b[0m \u001b[94mimport\u001b[0m process_image, process_directory                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m4 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mvideo_test\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m process_video\u001b[0m                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m5 \u001b[0m                                                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n",
            "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'src.video_test'\u001b[0m\n",
            "2025-04-13 15:57:39.710 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}